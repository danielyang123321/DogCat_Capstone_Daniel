{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Data Loading\n",
    "\n",
    "#read features and label data from csv file\n",
    "import pandas as pd\n",
    "train_features_final_df = pd.DataFrame(pd.read_csv(\"train_features_final.csv\")).drop('Unnamed: 0', axis=1)\n",
    "train_targets_final_df = pd.DataFrame(pd.read_csv(\"train_targets_final.csv\")).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#Split training dataset into training subset and testing subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_valid,y_train,y_valid= train_test_split(train_features_final_df,train_targets_final_df,test_size=0.3,random_state=0)\n",
    "\n",
    "#check train subset and validation subset\n",
    "#print(X_train.shape)\n",
    "#print(y_train.shape)\n",
    "#print(X_valid.shape)\n",
    "#print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 8066      \n",
      "=================================================================\n",
      "Total params: 8,066\n",
      "Trainable params: 8,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Building & Compling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "DogCat_model = Sequential()\n",
    "DogCat_model.add(Dense(2, input_shape=X_train.shape[1:], activation='softmax'))\n",
    "DogCat_model.summary()\n",
    "\n",
    "DogCat_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17002 samples, validate on 7287 samples\n",
      "Epoch 1/20\n",
      "17002/17002 [==============================] - 4s 258us/step - loss: 0.0563 - acc: 0.9924 - val_loss: 0.0396 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03961, saving model to model.v1.weights.best.hdf5\n",
      "Epoch 2/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0179 - acc: 0.9982 - val_loss: 0.0312 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03961 to 0.03116, saving model to model.v1.weights.best.hdf5\n",
      "Epoch 3/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0141 - acc: 0.9987 - val_loss: 0.0209 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03116 to 0.02088, saving model to model.v1.weights.best.hdf5\n",
      "Epoch 4/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0083 - acc: 0.9992 - val_loss: 0.0224 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02088\n",
      "Epoch 5/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0067 - acc: 0.9994 - val_loss: 0.0247 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02088\n",
      "Epoch 6/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0062 - acc: 0.9995 - val_loss: 0.0224 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02088\n",
      "Epoch 7/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0201 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02088 to 0.02008, saving model to model.v1.weights.best.hdf5\n",
      "Epoch 8/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0217 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02008\n",
      "Epoch 9/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0189 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02008 to 0.01887, saving model to model.v1.weights.best.hdf5\n",
      "Epoch 10/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0239 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01887\n",
      "Epoch 11/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01887\n",
      "Epoch 12/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0218 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01887\n",
      "Epoch 13/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01887\n",
      "Epoch 14/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01887\n",
      "Epoch 15/20\n",
      "17002/17002 [==============================] - 3s 192us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01887\n",
      "Epoch 16/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01887\n",
      "Epoch 17/20\n",
      "17002/17002 [==============================] - 3s 192us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01887\n",
      "Epoch 18/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01887\n",
      "Epoch 19/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01887\n",
      "Epoch 20/20\n",
      "17002/17002 [==============================] - 3s 193us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbdec33bf60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Training\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.v1.weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "DogCat_model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the best model\n",
    "DogCat_model.load_weights('model.v1.weights.best.hdf5')\n",
    "\n",
    "#read features data from csv file\n",
    "import pandas as pd\n",
    "test_features_df = pd.DataFrame(pd.read_csv(\"test_features.csv\")).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#generate predictions using features\n",
    "predicted_vector = DogCat_model.predict(test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to reduce absolute prediction\n",
    "def predict_adjust(x):\n",
    "    epsilon=0.005\n",
    "    if x>1-epsilon:\n",
    "        return 1-epsilon\n",
    "    if x<epsilon:\n",
    "        return epsilon\n",
    "    return x\n",
    "\n",
    "#try on test files\n",
    "#move all files to a directory names 'unlabeled'\n",
    "from sklearn.datasets import load_files     \n",
    "data = load_files('test')\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "test_files = np.array(data['filenames'])\n",
    "\n",
    "#store prediction list into csv files, using adjusted prediction\n",
    "kaggle_submission=[]\n",
    "for test_file,prediction in zip(test_files,predicted_vector):\n",
    "    kaggle_submission.append([test_file.replace('test/unlabeled/','').replace('.jpg',''),predict_adjust(prediction[1])])\n",
    "\n",
    "import pandas as pd\n",
    "kaggle_submission_df=pd.DataFrame(kaggle_submission, columns=['id','label'])\n",
    "kaggle_submission_df.to_csv('submission_v1.csv', index=False)\n",
    "\n",
    "#kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f submission_v1.csv -m \"model v1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
