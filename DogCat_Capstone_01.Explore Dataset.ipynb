{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This note book is used for exploring dataset.\n",
    "#这是用来对训练集数据进行探索的工作薄。\n",
    "\n",
    "#linux commands to move dog/cat pictures into seperate folders\n",
    "#使用linux命令将原始数据集移动到不同的文件夹\n",
    "#mkdir cat\n",
    "#find ./ -maxdepth 1 -name 'cat*.jpg' -exec mv {} ./cat \\;\n",
    "#mkdir dog\n",
    "#find ./ -maxdepth 1 -name 'dog*.jpg' -exec mv {} ./dog \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Load training dataset\n",
    "#加载训练图片数据集\n",
    "from sklearn.datasets import load_files     \n",
    "data = load_files('train')\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "train_files = np.array(data['filenames'])\n",
    "train_targets = np_utils.to_categorical(np.array(data['target']), 2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract dimension information from training dataset\n",
    "#从训练图片训练集提取图片维度信息\n",
    "import cv2\n",
    "train_dimensions_list = []\n",
    "for train_file in train_files:\n",
    "    img = cv2.imread(train_file)\n",
    "    dimensions = img.shape\n",
    "    train_dimensions_list.append([train_file,dimensions[0],dimensions[1],dimensions[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.00000</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>360.478080</td>\n",
       "      <td>404.09904</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>97.019959</td>\n",
       "      <td>109.03793</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>301.000000</td>\n",
       "      <td>323.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>374.000000</td>\n",
       "      <td>447.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>421.000000</td>\n",
       "      <td>499.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>1050.00000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              width       height    depth\n",
       "count  25000.000000  25000.00000  25000.0\n",
       "mean     360.478080    404.09904      3.0\n",
       "std       97.019959    109.03793      0.0\n",
       "min       32.000000     42.00000      3.0\n",
       "25%      301.000000    323.00000      3.0\n",
       "50%      374.000000    447.00000      3.0\n",
       "75%      421.000000    499.00000      3.0\n",
       "max      768.000000   1050.00000      3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dimensions\n",
    "#查看图片维度信息的统计数据\n",
    "import pandas as pd\n",
    "train_dimensions=pd.DataFrame(train_dimensions_list, columns = [\"train_file\", \"width\", \"height\", \"depth\"])\n",
    "train_dimensions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use tableau public to perform further analysis on csv file\n",
    "#将训练集图片维度信息存储为csv文件，在tableau中进一步可视化\n",
    "train_dimensions.to_csv('train_dimension.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check label error using pre-trained resnet50\n",
    "#this approach turned out to be not very efficient\n",
    "#使用keras的resnet50预训练模型来对图片进行预测，进而对训练集标签错误进行复核。\n",
    "#手工复核中发现这种方法带来的工作量太大，所以更改为使用更加先进的百度图片识别服务。\n",
    "#这部分代码仅仅留存在这里作为参考，没有被实际使用。\n",
    "\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "#from keras.preprocessing import image\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#import numpy as np\n",
    "\n",
    "#model = ResNet50(weights='imagenet')\n",
    "#train_labels = []\n",
    "\n",
    "#for train_file,train_target in zip(train_files,train_targets):\n",
    "#    img = image.load_img(train_file, target_size=(224, 224))\n",
    "#    x = image.img_to_array(img)\n",
    "#    x = np.expand_dims(x, axis=0)\n",
    "#    x = preprocess_input(x)\n",
    "#    preds = model.predict(x)\n",
    "#    train_labels.append([train_file, decode_predictions(preds, top=1)[0][0][1]])\n",
    "    \n",
    "#import pandas as pd\n",
    "#train_labels=pd.DataFrame(train_labels, columns = [\"train_file\", \"predict\"])\n",
    "#train_labels.to_csv('train_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use baidu ai to predict labels for training dataset.\n",
    "#使用百度图片识别服务来对训练集的图片进行标签预测\n",
    "\n",
    "#01.initialization\n",
    "#01.初始化\n",
    "from aip import AipImageClassify\n",
    "\n",
    "APP_ID = '' #value removed\n",
    "API_KEY = '' #value removed\n",
    "SECRET_KEY = '' #value removed\n",
    "\n",
    "client = AipImageClassify(APP_ID, API_KEY, SECRET_KEY)\n",
    "\n",
    "def get_file_content(filePath):\n",
    "    with open(filePath, 'rb') as fp:\n",
    "        return fp.read()\n",
    "\n",
    "train_labels_df = pd.DataFrame(pd.read_csv(\"train_label.csv\"),columns = ['train_file','predict'])\n",
    "train_labels = train_labels_df.values.tolist()\n",
    "predicted_files = train_labels_df['train_file'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d45dfed2c824ac7896f930a8cba9309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/cat/cat.10392.jpg\n",
      "{'log_id': 2214097746608673991, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.10733.jpg\n",
      "{'log_id': 3478175862374451154, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/cat/cat.5534.jpg\n",
      "{'log_id': 6767665921178003551, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.4367.jpg\n",
      "{'log_id': 9063937966059924784, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/cat/cat.6614.jpg\n",
      "{'log_id': 1846562680616028352, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.1324.jpg\n",
      "{'log_id': 6751093081619811531, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.9246.jpg\n",
      "{'log_id': 4213569367857841417, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.11248.jpg\n",
      "{'log_id': 8369342386938046913, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.2652.jpg\n",
      "{'log_id': 1822557284218531936, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/cat/cat.6402.jpg\n",
      "{'log_id': 2291895126866171638, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/cat/cat.4821.jpg\n",
      "{'log_id': 8497420167380499574, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.7011.jpg\n",
      "{'log_id': 7447992250935019301, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/cat/cat.5527.jpg\n",
      "{'log_id': 3287804653002675748, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.11686.jpg\n",
      "{'log_id': 8534943323339288752, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.9705.jpg\n",
      "{'log_id': 6515601262226801535, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/cat/cat.2433.jpg\n",
      "{'log_id': 6006911043478350644, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/cat/cat.9171.jpg\n",
      "{'log_id': 7967297938874992572, 'error_code': 216202, 'error_msg': 'image size error'}\n",
      "train/dog/dog.10747.jpg\n",
      "{'log_id': 5818072196806642305, 'error_code': 216202, 'error_msg': 'image size error'}\n"
     ]
    }
   ],
   "source": [
    "#use baidu ai to predict labels for training dataset.\n",
    "#使用百度图片识别服务来对训练集的图片进行标签预测\n",
    "\n",
    "#02.execution\n",
    "#02.执行标签预测\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "p = IntProgress()\n",
    "errorCount=0\n",
    "progressFull=train_files.size\n",
    "display(p)\n",
    "\n",
    "for train_file in train_files:\n",
    "    if train_file not in predicted_files:\n",
    "        image = get_file_content(train_file)\n",
    "        options = {}\n",
    "        options[\"top_num\"] = 1\n",
    "        try:\n",
    "            classifyResult=client.animalDetect(image, options)\n",
    "            train_labels.append([train_file,classifyResult['result'][0]['name']])            \n",
    "        except:\n",
    "            print(train_file)\n",
    "            print(classifyResult)\n",
    "            errorCount=errorCount+1\n",
    "            if errorCount==30:\n",
    "                break\n",
    "        else:\n",
    "            predicted_files.append(train_file)            \n",
    "            p.value = float(len(train_labels))/float(progressFull)*100\n",
    "            p.description = str(len(train_labels))+'/'+str(progressFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use baidu ai to predict labels for training dataset.\n",
    "#使用百度图片识别服务来对训练集的图片进行标签预测\n",
    "\n",
    "#03.store results for further analysis\n",
    "#02.将结果存储起来，然后做进一步分析\n",
    "import pandas as pd\n",
    "train_labels_df=pd.DataFrame(train_labels, columns = [\"train_file\", \"predict\"])\n",
    "train_labels_df.to_csv('train_label.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
