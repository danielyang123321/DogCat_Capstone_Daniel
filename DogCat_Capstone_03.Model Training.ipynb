{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Data Loading\n",
    "\n",
    "#read features and label data from csv file\n",
    "import pandas as pd\n",
    "train_features_final_df = pd.DataFrame(pd.read_csv(\"train_features_final.csv\")).drop('Unnamed: 0', axis=1)\n",
    "train_targets_final_df = pd.DataFrame(pd.read_csv(\"train_targets_final.csv\")).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#Split training dataset into training subset and testing subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_valid,y_train,y_valid= train_test_split(train_features_final_df,train_targets_final_df,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 4032)              16128     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 8066      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 24,194\n",
      "Trainable params: 16,130\n",
      "Non-trainable params: 8,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Building & Compling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "DogCat_model = Sequential()\n",
    "DogCat_model.add(BatchNormalization(input_shape=X_train.shape[1:]))\n",
    "DogCat_model.add(Dense(2))\n",
    "DogCat_model.add(Activation('softmax'))\n",
    "DogCat_model.summary()\n",
    "\n",
    "DogCat_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "plot_model(DogCat_model,to_file='model_v0.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17423 samples, validate on 7467 samples\n",
      "Epoch 1/100\n",
      "17423/17423 [==============================] - 2s 118us/step - loss: 0.9328 - acc: 0.5414 - val_loss: 0.0472 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04719, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 2/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0407 - acc: 0.9875 - val_loss: 0.0370 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04719 to 0.03704, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 3/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0317 - acc: 0.9923 - val_loss: 0.0327 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03704 to 0.03272, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 4/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0277 - acc: 0.9935 - val_loss: 0.0296 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03272 to 0.02955, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 5/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0248 - acc: 0.9941 - val_loss: 0.0271 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02955 to 0.02712, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 6/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0225 - acc: 0.9947 - val_loss: 0.0251 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02712 to 0.02515, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 7/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0206 - acc: 0.9950 - val_loss: 0.0235 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02515 to 0.02351, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 8/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0191 - acc: 0.9955 - val_loss: 0.0221 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02351 to 0.02213, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 9/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0178 - acc: 0.9956 - val_loss: 0.0209 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02213 to 0.02093, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 10/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0166 - acc: 0.9958 - val_loss: 0.0199 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02093 to 0.01989, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 11/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0156 - acc: 0.9960 - val_loss: 0.0190 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01989 to 0.01898, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 12/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0147 - acc: 0.9963 - val_loss: 0.0182 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01898 to 0.01816, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 13/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0139 - acc: 0.9964 - val_loss: 0.0174 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01816 to 0.01744, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 14/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0132 - acc: 0.9964 - val_loss: 0.0168 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01744 to 0.01678, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 15/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0125 - acc: 0.9965 - val_loss: 0.0162 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01678 to 0.01619, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 16/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0119 - acc: 0.9966 - val_loss: 0.0157 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01619 to 0.01565, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 17/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0113 - acc: 0.9968 - val_loss: 0.0152 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01565 to 0.01517, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 18/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0147 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01517 to 0.01472, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 19/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0103 - acc: 0.9971 - val_loss: 0.0143 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01472 to 0.01431, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 20/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.0139 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01431 to 0.01394, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 21/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.0136 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01394 to 0.01359, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 22/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0133 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01359 to 0.01327, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 23/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.0130 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01327 to 0.01298, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 24/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0127 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01298 to 0.01271, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 25/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0080 - acc: 0.9978 - val_loss: 0.0125 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01271 to 0.01246, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 26/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0122 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01246 to 0.01223, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 27/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0120 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01223 to 0.01202, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 28/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0070 - acc: 0.9983 - val_loss: 0.0118 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01202 to 0.01182, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 29/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0116 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01182 to 0.01164, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 30/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.0115 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01164 to 0.01148, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 31/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0062 - acc: 0.9986 - val_loss: 0.0113 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01148 to 0.01132, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 32/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0112 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.01132 to 0.01118, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 33/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0110 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01118 to 0.01105, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 34/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0109 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01105 to 0.01093, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 35/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0108 - val_acc: 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_loss improved from 0.01093 to 0.01081, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 36/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0051 - acc: 0.9989 - val_loss: 0.0107 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01081 to 0.01071, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 37/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0048 - acc: 0.9989 - val_loss: 0.0106 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01071 to 0.01062, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 38/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0105 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.01062 to 0.01053, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 39/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0104 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.01053 to 0.01045, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 40/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0043 - acc: 0.9991 - val_loss: 0.0104 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.01045 to 0.01038, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 41/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0103 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.01038 to 0.01031, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 42/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0102 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.01031 to 0.01025, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 43/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0102 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01025 to 0.01019, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 44/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.01019 to 0.01014, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 45/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01014 to 0.01009, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 46/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0033 - acc: 0.9994 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.01009 to 0.01005, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 47/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0100 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.01005 to 0.01001, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 48/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0030 - acc: 0.9995 - val_loss: 0.0100 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.01001 to 0.00998, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 49/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00998 to 0.00995, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 50/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00995 to 0.00992, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 51/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00992 to 0.00990, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 52/100\n",
      "17423/17423 [==============================] - 2s 99us/step - loss: 0.0025 - acc: 0.9997 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00990 to 0.00988, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 53/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0099 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00988 to 0.00986, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 54/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0022 - acc: 0.9998 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00986 to 0.00984, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 55/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0021 - acc: 0.9998 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00984 to 0.00983, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 56/100\n",
      "17423/17423 [==============================] - 2s 98us/step - loss: 0.0020 - acc: 0.9998 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00983 to 0.00982, saving model to model.v0.weights.best.hdf5\n",
      "Epoch 57/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00982\n",
      "Epoch 58/100\n",
      "17423/17423 [==============================] - 2s 97us/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00982\n",
      "Epoch 59/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0099 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00982\n",
      "Epoch 60/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0018 - acc: 0.9999 - val_loss: 0.0104 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00982\n",
      "Epoch 61/100\n",
      "17423/17423 [==============================] - 2s 96us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0105 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00982\n",
      "Epoch 00061: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "checkpointer = ModelCheckpoint(filepath='model.v0.weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
    "\n",
    "history=DogCat_model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          epochs=100, batch_size=X_train.shape[0], callbacks=[checkpointer,earlystopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check loss trend lines\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the best model\n",
    "DogCat_model.load_weights('model.v0.weights.best.hdf5')\n",
    "\n",
    "#read features data from csv file\n",
    "import pandas as pd\n",
    "test_features_df = pd.DataFrame(pd.read_csv(\"test_features.csv\")).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#generate predictions using features\n",
    "predicted_vector = DogCat_model.predict(test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try on test files\n",
    "#move all files to a directory names 'unlabeled'\n",
    "from sklearn.datasets import load_files     \n",
    "data = load_files('test')\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "test_files = np.array(data['filenames'])\n",
    "\n",
    "#store prediction list into csv files\n",
    "kaggle_submission=[]\n",
    "for test_file,prediction in zip(test_files,predicted_vector):\n",
    "    kaggle_submission.append([test_file.replace('test/unlabeled/','').replace('.jpg',''),prediction[1]])\n",
    "\n",
    "import pandas as pd\n",
    "kaggle_submission_df=pd.DataFrame(kaggle_submission, columns=['id','label'])\n",
    "kaggle_submission_df.to_csv('submission_v0.csv', index=False)\n",
    "\n",
    "#kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f submission_v0.csv -m \"model v0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to reduce absolute prediction\n",
    "def predict_adjust(x):\n",
    "    epsilon=0.005\n",
    "    if x>1-epsilon:\n",
    "        return 1-epsilon\n",
    "    if x<epsilon:\n",
    "        return epsilon\n",
    "    return x\n",
    "\n",
    "#try on test files\n",
    "#move all files to a directory names 'unlabeled'\n",
    "from sklearn.datasets import load_files     \n",
    "data = load_files('test')\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "test_files = np.array(data['filenames'])\n",
    "\n",
    "#store prediction list into csv files, using adjusted prediction\n",
    "kaggle_submission=[]\n",
    "for test_file,prediction in zip(test_files,predicted_vector):\n",
    "    kaggle_submission.append([test_file.replace('test/unlabeled/','').replace('.jpg',''),predict_adjust(prediction[1])])\n",
    "\n",
    "import pandas as pd\n",
    "kaggle_submission_df=pd.DataFrame(kaggle_submission, columns=['id','label'])\n",
    "kaggle_submission_df.to_csv('submission_v1.csv', index=False)\n",
    "\n",
    "#kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f submission_v1.csv -m \"model v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
